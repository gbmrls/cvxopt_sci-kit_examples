{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1 - SVM Basics.ipynb","provenance":[],"authorship_tag":"ABX9TyPmEWy4EIrEngJsex/CqToW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xv7cwWTw-v7_"},"source":["# Support Vector Machines\n","\n"]},{"cell_type":"code","metadata":{"id":"eFsly9tbZD9e"},"source":["from sklearn import svm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tz7wv9s8HahL"},"source":["## Classification\n","\n","SVC (Support Vector Classification), NuSVC and LinearSVC are classes capable of performing binary and multi-class classification on a dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgesMovH-PZW","executionInfo":{"status":"ok","timestamp":1618095031584,"user_tz":300,"elapsed":1480,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"292e9404-d401-46ac-d699-0be2ddd9adfb"},"source":["X = [[0, 0], [1, 1]]\n","y = [0, 1]\n","clf = svm.SVC()\n","clf.fit(X, y)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"3hNLK4Ax-iSh"},"source":["After being fitted, the model can then be used to predict new values:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaSOHO3J-U_l","executionInfo":{"status":"ok","timestamp":1618095033461,"user_tz":300,"elapsed":282,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"d39b7ebe-979b-4fbf-a870-01d658d84d37"},"source":["clf.predict([[2., 2.]])"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"AOEKdK7IAlXU"},"source":["SVMs decision functions depends on some subset of the training data, called the support vectors. Some properties of these support vectors can be found in attributes ```support_vectors_```, ```support_``` and ```n_support_```.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bR74K4jHG-fl","executionInfo":{"status":"ok","timestamp":1618097229016,"user_tz":300,"elapsed":280,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"17fbbbd2-5161-4f2f-f893-b22aeeabd2d7"},"source":["# get support vectors\n","clf.support_vectors_"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0.],\n","       [1., 1.]])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YfOkGIPqHFVX","executionInfo":{"status":"ok","timestamp":1618097247693,"user_tz":300,"elapsed":302,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"716fca78-f804-4eb5-da66-87a77f2299bf"},"source":["# get indices of support vectors\n","clf.support_"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sw_wpFwzHKnW","executionInfo":{"status":"ok","timestamp":1618097270146,"user_tz":300,"elapsed":276,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"a6ef8cd8-0f25-4879-cffa-0fca95a7a906"},"source":["# get number of support vectors for each class\n","clf.n_support_"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Rwe-EIqgHgCS"},"source":["### Multi-class classification\n","\n","SVC and NuSVC implement the \"one-versus-one\" approach for multi-class classification. In total, `n_classes * (n_classes - 1) / 2` classifiers are constructed and each one trains data from two classes. To provide a consistent interface with other classifiers, the `decision_function_shape` option allows to monotonically transform the results of the \"one-versus-one\" classifiers to a \"one-vs-rest\" decision function of shape `(n_classes, n_classes)`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"501xjvgyID6u","executionInfo":{"status":"ok","timestamp":1618097639678,"user_tz":300,"elapsed":286,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"f8dc1564-bd87-4bde-fdf3-0093130c78ca"},"source":["X = [[0], [1], [2], [3]]\n","Y = [0, 1, 2, 3]\n","clf = svm.SVC(decision_function_shape='ovo')\n","clf.fit(X, Y)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEXGNsRMIp9g","executionInfo":{"status":"ok","timestamp":1618097672343,"user_tz":300,"elapsed":301,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"b8324da9-f07d-4378-f05a-d5277f8b55c7"},"source":["dec = clf.decision_function([[1]])\n","dec.shape[1]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hB5STyEUIx3P","executionInfo":{"status":"ok","timestamp":1618098266318,"user_tz":300,"elapsed":281,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"aa67cf21-fdc6-4377-d5ee-fddf2dcc6f56"},"source":["clf.decision_function_shape = \"ovr\"\n","dec = clf.decision_function([[1]])\n","dec.shape[1]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"q_0tuSOXLFfu"},"source":["Linear SVC implements \"one-vs-the-rest\" multi-class strategy, thus training `n_classes` models."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRPl9eKQLMy0","executionInfo":{"status":"ok","timestamp":1618098363077,"user_tz":300,"elapsed":345,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"c2fe469b-b59b-44cf-e2c6-bcb6cfff3ded"},"source":["lin_clf = svm.LinearSVC()\n","lin_clf.fit(X, Y)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n","          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n","          verbose=0)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6uxcHlJLkT0","executionInfo":{"status":"ok","timestamp":1618098431737,"user_tz":300,"elapsed":275,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"b6b3e464-2649-44d3-f18b-14b55b91771d"},"source":["dec = lin_clf.decision_function([[1]])\n","dec.shape[1]"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"DGevWtN7Lf4b"},"source":["Linear SVC can also implement an alternative multi-class strategy: the so-called multi-class SVM formulated by Crammer and Singer. This is done by setting the option `multi_class='crammer_singer'`.\n","\n","For \"one-vs-rest\" LinearSVC the attribues `coef_` and `intercept_` have the shape `(n_classes, n_features)` and `(n_classes,)` respectively. Each row of the coefficients corresponds to one of the `n_classes` \"one-vs-rest\" classifiers and similar for the intercepts, in the order of the \"one\" class.\n","\n","The shape of `dual_coef_` is `(n_classes-1, n_SV)`."]},{"cell_type":"markdown","metadata":{"id":"qoRIPdMfMo0X"},"source":["### Scores and probabilities\n","\n","The `decision_function` method of SVC and NuSVC gives per-class scores for each sample (or a single score per sample in the binary case). When the constructor option `probability` is set to `True`, class membership probability estimates (from the methods `predict_proba` and `predict_log_proba`) are enabled.\n","\n","In the binary case, the probabilities are calibrated using Platt scaling, known to have theoretical issues. If confidence scores are required, but these do not have to be probabilities, then it's advisable to set `probability=False` and use `decision_function` instead of `predict_proba`."]},{"cell_type":"markdown","metadata":{"id":"tVf_8PRvU_u-"},"source":["### Unbalanced problems\n","\n","In problems where it's desired to give more importance to certain classes or certain individual samples, the parameters `class_weight` and `sample_weight` can be used.\n","\n","SVC implements the parameter `class_weight` in the `fit` method. It's a dictionary of the form `{class_label : value}`, where value is a floating point number > 0 that sets the parameter `C` of class `class_label` to `C * value`. \n","\n","SVC, NuSVC, SVR, NuSVR, LinearSVC, LinearSVR and OneClassSVM implement also weights for individual samples in the `fit` method through the `sample_weight` parameter. Similar to `class_weight`, this sets the parameter `C` for the i-th example to `C * sample_weight[i]`, which will encourage the classifier to get these samples right. (Check problem 1.7)"]},{"cell_type":"markdown","metadata":{"id":"Rm6_ZskJYXch"},"source":["## Regression\n","\n","The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.\n","\n","There are three different implementations of Support Vector Regression: SVR, NuSVR and LinearSVR. LinearSVR only considers the linear kernel.\n","\n","As with classification classes, the fit method will take as argument vectors $X$, $y$, only that in this case $y$ is expected to have floating point values instead of integer values:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bxeGo2eY_jf","executionInfo":{"status":"ok","timestamp":1618102018228,"user_tz":300,"elapsed":273,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"e50e68db-e710-468a-e6f3-db25d3aced0b"},"source":["X = [[0, 0], [2, 2]]\n","y = [0.5, 2.5]\n","regr = svm.SVR()\n","regr.fit(X, y)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n","    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDHtRWYxZXWb","executionInfo":{"status":"ok","timestamp":1618102039010,"user_tz":300,"elapsed":269,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"9f22815b-9654-4765-c9fe-9467af1c0603"},"source":["regr.predict([[1, 1]])"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.5])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"ND7EZookZwXe"},"source":["## Tips on practical use\n","\n","*   **Avoiding data copy:** Check that the data is C-ordered contiguous and double precision, else it will be copied when calling the C implementation. You can check whether a given numpy array is C-contiguous by inspecting its `flags` attribute.\n","*   **Kernel cache size:** The size of the kernel cache has a strong impact on run times for larger problems. `cache_size` can be modified to a higher value than the default of 200 MB.\n","*   **Setting C:** `C` is `1` by default. If you have a lot of noisy observations you should decrease it (more regularization).\n","*   ***Scale your data:** SVM algorithms are not scale invariant (don't forget to scale your test vector too). Check [here](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) for more info on preprocessing with sklearn.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fIpRP7cTcBw_"},"source":["## Kernel functions\n","\n","The *kernel* can be any of the following:\n","*   linear: $\\langle x, x' \\rangle$\n","*   polynomial: $(\\varphi \\langle x, x' \\rangle + r)^d$, where $d$ is specified by parameter `degree`, r by `coef0`\n","*   rbf: $\\exp(-\\gamma ||x-x'||^2) $, where $\\gamma$ is specified by `gamma` > 0\n","*   sigmoid: $ \\tanh (\\varphi \\langle x, x' \\rangle + r)$, where $r$ is specified by `coef0`\n","\n","Kernels are specified by the `kernel` parameter:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MZc8rSH7bmxy","executionInfo":{"status":"ok","timestamp":1618103858303,"user_tz":300,"elapsed":298,"user":{"displayName":"Gabriel Morales Ruiz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhbbBhwcqtK_IaxYDcV6mQBNbqc3yU4AQN1FA5M1w=s64","userId":"11041153241480127246"}},"outputId":"3055b18e-a567-4a1d-dbe3-1327eaf4c139"},"source":["linear_svc = svm.SVC(kernel=\"linear\")\n","linear_svc.kernel"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'linear'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"bn5iCFq3gapy"},"source":["### Custom Kernels\n","\n","You can define your own kernels by either giving the kernel as a python function (e.g. `svm.SVC(kernel=function_name)`) or by precomputing the Gram matrix. \n","\n","Custom kernel example [here](https://scikit-learn.org/stable/auto_examples/svm/plot_custom_kernel.html).\n","\n","#### Using the Gram matrix\n","\n","* Use `kernel=\"precomputed\"` and pass the Gram matrix instead of $X$ to the `fit` and `predict` methods. The kernel values between *all* training vectors and the test vectors must be provided."]},{"cell_type":"markdown","metadata":{"id":"Ya2rqAKPhf_Y"},"source":["# Reference\n","https://scikit-learn.org/stable/modules/svm.html"]}]}